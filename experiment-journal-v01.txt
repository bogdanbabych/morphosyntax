[[github commands]]
	
1. create new repository
	https://github.com/new
	
2. copy clone link:
	from repository homepage
		https://github.com/bogdanbabych/morphosyntax
	https://github.com/bogdanbabych/morphosyntax.git
	git@github.com:bogdanbabych/morphosyntax.git
	
3. cd to directory
	cd /Users/bogdan/espace/pr201611morphosyntax/morphosyntax
	
4. for moving to a new directory, e.g., external hard drive or a server:
	git clone https://github.com/bogdanbabych/morphosyntax.git
	
5. checking status
	# change to the directory morphosyntax with the .git file
	/Users/bogdan/espace/pr201611morphosyntax/morphosyntax
	git status
	
6. checking differences for files
	diff md070crosslevenshteinPhonV02TopCand.py md070crosslevenshteinPhonV03TopCzech.py
	
	
7. Adding
	git add *
	git add -A .

8. Committing
	git commit -m "message"
	
	>> if hit
	git commit
		without a message, then press:
		ESC + :wq + ENTER

9. Pushing
	git push

10. Pulling
	git pull
	
11. Discarding changes
	git checkout
	
+ user rsync to synchronise data folders...


[[Morphosyntax project]]
Goal: develop a coherent model of 

14/11/2016
The project is developing a cognate identification metric via computing phonological levenshtein distance

Tasks
	- re-engineer matching modules (currently phonological representations is computed many times for the same word in a longer dictionary; cash phonological representation?)

	- write in a 'distributionally clean' way

15/11/2016
next stage:
	error analysis:
		- find the scripts which can trace back for each pair of cognates how phonological distance has been computed


9/12/2016
	principle: keep a run separate in a non-synchronised directory:
		important for multiple non-development related splits...
		

14/12/2016
	task: debugging Ukrainian system
	task: developing a proper engineering framework
		>> modules for processing and self-documentation/evaluation....
		>> calibrating thresholds
		>> testing feature structures, use of the table / hierarchy;
		>> replicating results reported in previous experiments
			>> to set up the issue of replicability of the results...
			
	task: debug: output only top N items... >> cashing the tables for each item, or re-running them ??? 
	>>> top scores and then calling the module wiht the debug turned on


04/01/2017
	recreate run / development path
	develop evaluation sets
	optimising the development >> finding cognates; understanding limits...
	
	engineering for output design... 
	>> translating Ukrainian word forms...
	>> vision: Ukrainian morphosyntax... 
		
		
[[todo]]
	9/12/2016
	1. run for Ukrainian and Russian; 
		run for Czech and Russian;
		
	2. develop a system for error detection
	
	3. optimising for speed...
	
	
	>> Ukrainian corpus:
		- capitalization problem...
		- language detection problem...
		
		
		
[[STAGES]]

	0. creating Ukrainian NUM file:
		cwb-scan-corpus -C INTERNET-UA word pos | sort -nr -k 1 > internet-ua-num.txt
		cwb-decode -C INTERNET-UA -ALL > internet-ua-out.txt
		cwb-decode -P word -P pos -P lemma INTERNET-UA > internet-ua-out.txt
		cwb-decode -h
		
		// cwb-decode INTERNET-UA
		// cwb-decode -P word -P lemma -P POS INTERNET-UA
		// 
		
		Serge's suggestion:
			cwb-decode -C INTERNET-UA -P word -P pos | sed -r 's/\t([A-Z]).+/\t\1/' | gawk '{print(tolower($0))}' | sort | uniq -c | sort -nr -k 1 >uk-forms.num
		
		
		// identified problems:
		a. capitalization
		b. russian words / letters in the corpus
		

	1. Debugging:
		head -n 1000000 <V04uk2k-1052x-md050crosslevenshtein.debug | tail -n 10000 >V04uk2k-1052x-md050crosslevenshteinH10k-mid1m.debug
		tail -n 10000 <V04uk2k-1052x-md050crosslevenshtein.debug >V04uk2k-1052x-md050crosslevenshteinT10k.debug
		command to select debug info...
		
	
	task: 
		to return all items of the same top rank;
			>> baseline and graphonological... >>
			remove frequency filter; only use PoS filter...
			
		return several items ... of the same rank == calculating ranks;
		speed up of calculation:
			>> comparing vector spaces:
				>> the concept of the vector subspace...
				>> can this be modelled by structure feature representation...
				
	
	4/01/2017
	solution: the problem is in the filter
	
		

===========

records for the paper on evaluation and topology of features:
goal: to establish a framework for evaluation topology of features
	>> on the basis of lists of cognates
	
	1. evaluation scenario
		- read cognates produced/found by my algorithm --> 2 ways: 
			- top 1 and top 10 >>
		- read cognates from the evaluation set;
		- compare;
		
		-- generate ~ 3000
		
		// critical point: to re-run the algorithm...
		// run on a cluster and re-generate ...
	2. producing evaluation results
	3. producing configurations
	4. testing configurations
	
	
	
	
	
	
	

			